### Project Title & Description
**Project Title:** Agentic RAG Chatbot for Ethiopian Women's Health

**Description:** I'm building an AI chatbot designed to be a reliable source of information for Ethiopian women on critical health issues, including maternal health, obstetric fistula, and various cancers. The goal is to provide accessible, accurate, and culturally relevant health information, which is a major challenge in many parts of Ethiopia. This chatbot will act as an agentic retrieval-augmented generation (RAG) system, meaning it will use an AI agent to intelligently retrieve information from a curated knowledge base (rather than just its pre-trained data) and then formulate a helpful and empathetic response.

This matters because it can help bridge the information gap in healthcare, empowering women with knowledge to make informed decisions about their well-being. By leveraging a targeted knowledge base, the chatbot will ensure the information is not only correct but also relevant to the local context, addressing specific challenges faced by women in Ethiopia.

***

### Tech Stack
* **Backend:** FastAPI
* **Vector Database:** FAISS
* **Database:** Supabase
* **AI Orchestration Framework:** LangGraph
* **Frontend:** Next.js

***

### AI Integration Strategy
I'll use AI throughout the development process to enhance productivity and code quality.

#### ðŸ§± Code or Feature Generation
I'll use an AI assistant, like Cursor, to scaffold foundational components and functions. This includes:

* **API Endpoints:** Generating the initial FastAPI routes and request/response models based on a description of the desired functionality (e.g., "Create a FastAPI endpoint at `/chat` that accepts a user message and returns a chatbot response.").
* **Database Models:** Creating SQLAlchemy models and Supabase schema definitions from a simple description of the data structure (e.g., "Generate a Supabase schema for a `user_conversations` table with columns for `user_id`, `timestamp`, `message`, and `bot_response`.").
* **Frontend Components:** Scaffolding the basic Next.js components for the chat interface, including input fields and message display lists.

#### ðŸ§ª Testing Support
I'll leverage AI to accelerate the testing phase by generating test suites.

* **Unit Tests:** I'll use prompts to generate unit tests for individual functions and classes, ensuring they behave as expected. For instance, I'll ask for tests that check edge cases, such as empty input or invalid data formats, for my LangGraph nodes or FastAPI routes.
* **Integration Tests:** The AI will assist in creating tests that verify the entire system flow, from the Next.js frontend making a request to the FastAPI backend, through the LangGraph and FAISS pipeline, and back to the user interface.

#### ðŸ“¡ Schema-Aware
Given the use of a REST API with FastAPI and a database with Supabase, AI will be invaluable for maintaining schema consistency.

* I'll feed the OpenAPI specification generated by FastAPI to the AI to help generate new functions and data models that adhere to the existing schema. This prevents errors and ensures my code is always in sync with the API contract.
* For the Supabase database, I'll use the schema to prompt the AI to generate the correct SQL or ORM code for data insertion, retrieval, and updates, ensuring every database interaction is valid.

***

### In-Editor/PR Review Tooling
I'll use **CodeRabbit** for in-editor and PR review tooling. I chose CodeRabbit because of its ability to provide detailed, line-by-line feedback that closely mimics a senior developer's input. It integrates directly with my GitHub repository.

* **PR Reviews:** CodeRabbit will automatically analyze my pull requests and provide comments on potential bugs, code smells, or areas for improvement. This will catch issues early and streamline the review process with my collaborators.
* **Writing Commit Messages:** I'll use a CodeRabbit-like agent to help me draft clear and concise commit messages and PR descriptions by summarizing the changes I've made in the code.

***

### Prompting Strategy
My prompting strategy will focus on being highly specific and providing context to ensure the AI's output is accurate and relevant to my project's architecture. I'll use a "few-shot" approach where I provide a small example to guide the AI's output format.

**Sample Prompts:**

* "Generate a test suite for the `send_message` authentication function in `auth.py`, ensuring it handles valid and invalid JWT tokens and returns the correct HTTP status codes for each case. The function signature is `def send_message(message: str, token: str = Depends(oauth2_scheme)):`"
* "Based on this FastAPI OpenAPI spec, generate a new Pydantic request model for a `/health_info` endpoint that takes a `symptom` string and an optional `location` string, and generates a response model that includes `information_text` and a list of `source_documents`."
